# ──────────────────────────────────────────────────────────────
# Ouroboros — Environment Variables Template
# Copy this file to .env and fill in the values you need.
# ──────────────────────────────────────────────────────────────

# ── LLM Provider ──────────────────────────────────────────────
# Default provider: Ollama (local), openai, anthropic
PIPELINE__LlmProvider__DefaultProvider=Ollama
PIPELINE__LlmProvider__OllamaEndpoint=http://localhost:11434
PIPELINE__LlmProvider__DefaultChatModel=llama3:latest
PIPELINE__LlmProvider__DefaultEmbeddingModel=nomic-embed-text
PIPELINE__LlmProvider__RequestTimeoutSeconds=120

# ── API Keys (leave blank if not using that provider) ─────────
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GITHUB_TOKEN=

# ── Generic chat endpoint (for OpenAI-compatible services) ────
CHAT_ENDPOINT=
CHAT_API_KEY=
CHAT_ENDPOINT_TYPE=

# ── Vector Store ──────────────────────────────────────────────
# Type: InMemory, Qdrant, Pinecone
PIPELINE__VectorStore__Type=InMemory
PIPELINE__VectorStore__BatchSize=100
PIPELINE__VectorStore__DefaultCollection=pipeline_vectors

# Qdrant (only needed when VectorStore__Type=Qdrant)
QDRANT__ENDPOINT=http://localhost:6333

# ── Pipeline Execution ────────────────────────────────────────
PIPELINE__Execution__MaxTurns=5
PIPELINE__Execution__MaxParallelToolExecutions=5
PIPELINE__Execution__EnableDebugOutput=false
PIPELINE__Execution__ToolExecutionTimeoutSeconds=60

# ── Observability ─────────────────────────────────────────────
PIPELINE__Observability__EnableStructuredLogging=true
PIPELINE__Observability__MinimumLogLevel=Information
PIPELINE__Observability__EnableMetrics=false
PIPELINE__Observability__EnableTracing=false

# ── ASP.NET Core (WebAPI) ─────────────────────────────────────
ASPNETCORE_ENVIRONMENT=Development
ASPNETCORE_URLS=http://+:8080
