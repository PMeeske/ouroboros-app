{
  "ApiKeys": {
    "Firecrawl": "",
    "SerpApi": "",
    "OpenAI": "",
    "Anthropic": ""
  },
  "Pipeline": {
    "LlmProvider": {
      "DefaultProvider": "Ollama",
      "OllamaEndpoint": "http://localhost:11434",
      "DefaultChatModel": "deepseek-v3.1:671b-cloud",
      "DefaultEmbeddingModel": "nomic-embed-text",
      "RequestTimeoutSeconds": 120
    },
    "VectorStore": {
      "Type": "InMemory",
      "BatchSize": 100,
      "DefaultCollection": "pipeline_vectors"
    },
    "Execution": {
      "MaxTurns": 5,
      "MaxParallelToolExecutions": 5,
      "EnableDebugOutput": false,
      "ToolExecutionTimeoutSeconds": 60
    },
    "Observability": {
      "EnableStructuredLogging": true,
      "MinimumLogLevel": "Information",
      "EnableMetrics": false,
      "EnableTracing": false
    }
  },
  "Serilog": {
    "Using": [ "Serilog.Sinks.Console", "Serilog.Sinks.File" ],
    "MinimumLevel": {
      "Default": "Information",
      "Override": {
        "Microsoft": "Warning",
        "System": "Warning"
      }
    },
    "WriteTo": [
      {
        "Name": "Console",
        "Args": {
          "outputTemplate": "[{Timestamp:HH:mm:ss} {Level:u3}] {Message:lj}{NewLine}{Exception}"
        }
      },
      {
        "Name": "File",
        "Args": {
          "path": "logs/pipeline-.log",
          "rollingInterval": "Day",
          "retainedFileCountLimit": 7,
          "outputTemplate": "{Timestamp:yyyy-MM-dd HH:mm:ss.fff zzz} [{Level:u3}] {Message:lj} {Properties:j}{NewLine}{Exception}"
        }
      }
    ],
    "Enrich": [ "FromLogContext", "WithMachineName", "WithThreadId" ]
  },
  "MultiModelPresets": {
    "anthropic-ollama": {
      "Name": "anthropic-ollama",
      "Description": "Anthropic Claude as master orchestrator with local Ollama specialized sub-models",
      "MasterRole": "general",
      "DefaultTemperature": 0.7,
      "DefaultMaxTokens": 2048,
      "TimeoutSeconds": 120,
      "EnableMetrics": true,
      "Models": [
        {
          "Role": "general",
          "ModelName": "claude-sonnet-4-20250514",
          "ProviderType": "anthropic",
          "Endpoint": "https://api.anthropic.com/v1",
          "ApiKeyEnvVar": "ANTHROPIC_API_KEY",
          "Temperature": 0.7,
          "MaxTokens": 4096,
          "Tags": [ "conversation", "general-purpose", "versatile", "planning", "orchestration" ],
          "AvgLatencyMs": 2000
        },
        {
          "Role": "coder",
          "ModelName": "deepseek-coder:33b",
          "ProviderType": "ollama",
          "Endpoint": "http://localhost:11434",
          "Temperature": 0.2,
          "MaxTokens": 8192,
          "Tags": [ "code", "programming", "debugging", "syntax", "refactoring" ],
          "AvgLatencyMs": 3000
        },
        {
          "Role": "reasoner",
          "ModelName": "deepseek-r1:32b",
          "ProviderType": "ollama",
          "Endpoint": "http://localhost:11434",
          "Temperature": 0.3,
          "MaxTokens": 4096,
          "Tags": [ "reasoning", "analysis", "logic", "explanation", "math" ],
          "AvgLatencyMs": 4000
        },
        {
          "Role": "summarizer",
          "ModelName": "llama3",
          "ProviderType": "ollama",
          "Endpoint": "http://localhost:11434",
          "Temperature": 0.3,
          "MaxTokens": 2048,
          "Tags": [ "summarization", "compression", "extraction" ],
          "AvgLatencyMs": 1500
        }
      ]
    }
  },
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft": "Warning",
      "Microsoft.Hosting.Lifetime": "Information"
    }
  },
  "Tapo": {
    "ServerAddress": "http://localhost:8000",
    "Username": "philip.meeske@oulook.com",
    "Password": "S1l3nC31987.",
    "Devices": [
      {
        "name": "Camera1",
        "device_type": "C200",
        "ip_addr": "192.168.50.29"
      }
    ]
  }
}
